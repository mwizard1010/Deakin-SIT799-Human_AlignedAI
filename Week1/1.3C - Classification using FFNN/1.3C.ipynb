{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GitHub [link](https://github.com/mwizard1010/Deakin-SIT799-Human_AlignedAI)!\n",
    "- Name:  Hung Son Nguyen\n",
    "- Student ID:  220069106\n",
    "- Email:  hsngu@deakin.edu.au"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to your assignment this week! \n",
    "\n",
    "\n",
    "# Classification task\n",
    "\n",
    "In this task you are asked to build a simple Feed Forward Neural Network, train it and test it!\n",
    "\n",
    "\n",
    "**After this assignment you will be able to:**\n",
    "\n",
    "- Load a dataset.\n",
    "- Train a Feed Forward Neural Network.\n",
    "- Test a Feed Forward Neural Network.\n",
    "\n",
    "Let's get started! Run the following cell to install all the packages you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./opt/anaconda3/lib/python3.7/site-packages (1.18.1)\n",
      "Requirement already satisfied: keras in ./opt/anaconda3/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: six>=1.9.0 in ./opt/anaconda3/lib/python3.7/site-packages (from keras) (1.14.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in ./opt/anaconda3/lib/python3.7/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in ./opt/anaconda3/lib/python3.7/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: h5py in ./opt/anaconda3/lib/python3.7/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in ./opt/anaconda3/lib/python3.7/site-packages (from keras) (5.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in ./opt/anaconda3/lib/python3.7/site-packages (from keras) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.14 in ./opt/anaconda3/lib/python3.7/site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: tensorflow in ./opt/anaconda3/lib/python3.7/site-packages (2.2.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.28.1)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.18.1)\n",
      "Requirement already satisfied: gast==0.3.3 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: six>=1.12.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (2.2.1)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (46.0.0.post20200309)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.14.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./opt/anaconda3/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.25.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.1.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in ./opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in ./opt/anaconda3/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./opt/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in ./opt/anaconda3/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in ./opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pandas in ./opt/anaconda3/lib/python3.7/site-packages (1.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in ./opt/anaconda3/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in ./opt/anaconda3/lib/python3.7/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in ./opt/anaconda3/lib/python3.7/site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: six>=1.5 in ./opt/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: matplotlib in ./opt/anaconda3/lib/python3.7/site-packages (3.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in ./opt/anaconda3/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./opt/anaconda3/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./opt/anaconda3/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in ./opt/anaconda3/lib/python3.7/site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: numpy>=1.11 in ./opt/anaconda3/lib/python3.7/site-packages (from matplotlib) (1.18.1)\n",
      "Requirement already satisfied: six>=1.5 in ./opt/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib) (1.14.0)\n",
      "Requirement already satisfied: setuptools in ./opt/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (46.0.0.post20200309)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to load the packages you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we will use consists of 4500 examples with 512 features. A label is given for each example to indicate positive and negative instances.\n",
    "\n",
    "Let's read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           v1       v2       v3       v4       v5       v6       v7       v8  \\\n",
      "id                                                                             \n",
      "1     0.37797 -0.94808  0.01346  0.17893  0.37795  0.63571  0.13943 -0.25607   \n",
      "2     0.07609 -0.09774  0.39666 -0.39026  0.10606  0.52774  0.07105  0.33720   \n",
      "3     1.19391 -0.68707 -0.68422 -0.36378 -0.60847 -0.40118  1.45432  0.00592   \n",
      "4     1.34949 -0.31498 -1.30248  0.50278  1.66292 -1.06094 -0.70835 -0.24237   \n",
      "5    -0.03512 -0.34196  0.14230  1.50513 -0.14364  0.49429  0.07823 -0.04356   \n",
      "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
      "4496  0.54554  0.63002  1.99328 -0.73290 -0.28964  0.61707  0.69515  0.87060   \n",
      "4497 -0.26235  0.50776 -0.74164 -0.52717 -0.35846 -1.16202  0.21828  0.22305   \n",
      "4498 -0.81564 -0.46034 -0.40044  0.21816  0.75283 -0.58075 -0.38389  0.26561   \n",
      "4499  0.09764 -0.05440 -1.53883 -0.04827 -0.60092 -1.20086  0.54661 -0.45875   \n",
      "4500  0.48335  1.66099 -1.98407  0.04818 -0.17309  1.06795  0.30303 -0.45490   \n",
      "\n",
      "           v9      v10  ...     v504     v505     v506     v507     v508  \\\n",
      "id                      ...                                                \n",
      "1    -0.39341  1.08947  ... -0.03494  1.32443 -0.94570  0.02055 -1.23908   \n",
      "2     0.69917 -0.02842  ...  0.86624 -1.24953 -0.21511 -1.54146  1.04765   \n",
      "3     1.68940 -0.98205  ... -0.35893  0.02330  0.31548 -0.34923 -0.41772   \n",
      "4    -0.15509 -0.04532  ...  0.23942  0.20774  0.81792 -0.74814 -0.62521   \n",
      "5     0.42009 -0.88828  ... -1.78407  0.07465  1.50182 -0.41289 -0.55908   \n",
      "...       ...      ...  ...      ...      ...      ...      ...      ...   \n",
      "4496  0.18784 -0.53365  ... -0.91652  0.24407  1.02312 -1.06633  0.06479   \n",
      "4497 -0.78329  0.09361  ...  0.86871 -0.09672 -0.32991 -0.69076 -0.40691   \n",
      "4498 -0.80443  0.49042  ... -0.22298  0.14621 -0.45917  0.69664  0.08561   \n",
      "4499 -0.11255  0.42889  ... -0.39275 -0.47806  0.58785  0.59169 -0.05488   \n",
      "4500 -1.83532 -0.75861  ... -0.11633  0.71603  1.20805 -0.44330  1.13303   \n",
      "\n",
      "         v509     v510     v511     v512  label  \n",
      "id                                               \n",
      "1     0.43507  1.08635  1.69027  0.61609      0  \n",
      "2    -1.24035  0.00866 -1.27640 -0.60496      1  \n",
      "3    -0.58175 -0.60177  0.43555  0.41982      1  \n",
      "4     0.01689  0.83997 -0.46986  0.06755      0  \n",
      "5    -0.29702  0.83641  0.59756 -0.20298      0  \n",
      "...       ...      ...      ...      ...    ...  \n",
      "4496  0.80146  0.57461  1.69958  0.43941      0  \n",
      "4497 -0.56606 -0.33767 -0.01251  0.06872      0  \n",
      "4498 -0.42261  0.14222  0.10394 -0.33635      1  \n",
      "4499 -0.81097 -0.25393  0.84022 -0.13068      1  \n",
      "4500 -0.14939  0.06201 -2.24746  0.17192      0  \n",
      "\n",
      "[4500 rows x 513 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.set_index('id', inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.index.values,\n",
    "    df.label.values,\n",
    "    test_size=0.15,\n",
    "    random_state=17,\n",
    "    stratify=df.label.values\n",
    ")\n",
    "df['data_type'] = ['note_set']*df.shape[0]\n",
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_test, 'data_type'] = 'test'\n",
    "\n",
    "## The data to use:\n",
    "\n",
    "X_train = df[df['data_type']=='train'].iloc[:,:512].values\n",
    "X_test = df[df['data_type']=='test'].iloc[:,:512].values\n",
    "y_train = df[df['data_type']=='train'].iloc[:,512:513].values\n",
    "y_test = df[df['data_type']=='test'].iloc[:,512:513].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "Build a Feed Forward Neural Network to address this classification task using the Keras framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START YOUR CODE HERE\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Now, let's start our training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3825/3825 [==============================] - 0s 67us/step - loss: 0.1768 - accuracy: 0.9273\n",
      "Epoch 2/200\n",
      "3825/3825 [==============================] - 0s 39us/step - loss: 0.0152 - accuracy: 0.9995\n",
      "Epoch 3/200\n",
      "3825/3825 [==============================] - 0s 40us/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "3825/3825 [==============================] - 0s 42us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "3825/3825 [==============================] - 0s 38us/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "3825/3825 [==============================] - 0s 37us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "3825/3825 [==============================] - 0s 66us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "3825/3825 [==============================] - 0s 49us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "3825/3825 [==============================] - 0s 40us/step - loss: 8.5155e-04 - accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "3825/3825 [==============================] - 0s 39us/step - loss: 6.9925e-04 - accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "3825/3825 [==============================] - 0s 39us/step - loss: 5.8396e-04 - accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "3825/3825 [==============================] - 0s 43us/step - loss: 4.9445e-04 - accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "3825/3825 [==============================] - 0s 42us/step - loss: 4.2508e-04 - accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "3825/3825 [==============================] - 0s 38us/step - loss: 3.6868e-04 - accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "3825/3825 [==============================] - 0s 38us/step - loss: 3.2271e-04 - accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "3825/3825 [==============================] - 0s 39us/step - loss: 2.8470e-04 - accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "3825/3825 [==============================] - 0s 39us/step - loss: 2.5299e-04 - accuracy: 1.0000\n",
      "Epoch 18/200\n",
      "3825/3825 [==============================] - 0s 38us/step - loss: 2.2615e-04 - accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "3825/3825 [==============================] - 0s 38us/step - loss: 2.0325e-04 - accuracy: 1.0000\n",
      "Epoch 20/200\n",
      "3825/3825 [==============================] - 0s 39us/step - loss: 1.8370e-04 - accuracy: 1.0000\n",
      "Epoch 21/200\n",
      "3825/3825 [==============================] - 0s 63us/step - loss: 1.6646e-04 - accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "3825/3825 [==============================] - 0s 42us/step - loss: 1.5165e-04 - accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "3825/3825 [==============================] - 0s 39us/step - loss: 1.3861e-04 - accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "3825/3825 [==============================] - 0s 39us/step - loss: 1.2711e-04 - accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "3825/3825 [==============================] - 0s 39us/step - loss: 1.1682e-04 - accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "3825/3825 [==============================] - 0s 39us/step - loss: 1.0776e-04 - accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "3825/3825 [==============================] - 0s 44us/step - loss: 9.9605e-05 - accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "3825/3825 [==============================] - 0s 41us/step - loss: 9.2288e-05 - accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "3825/3825 [==============================] - 0s 47us/step - loss: 8.5764e-05 - accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "3825/3825 [==============================] - 0s 61us/step - loss: 7.9765e-05 - accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "3825/3825 [==============================] - 0s 57us/step - loss: 7.4356e-05 - accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "3825/3825 [==============================] - 0s 56us/step - loss: 6.9472e-05 - accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "3825/3825 [==============================] - 0s 40us/step - loss: 6.4979e-05 - accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "3825/3825 [==============================] - 0s 39us/step - loss: 6.0869e-05 - accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "3825/3825 [==============================] - 0s 44us/step - loss: 5.7136e-05 - accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "3825/3825 [==============================] - 0s 52us/step - loss: 5.3658e-05 - accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "3825/3825 [==============================] - 0s 39us/step - loss: 5.0469e-05 - accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "3825/3825 [==============================] - 0s 39us/step - loss: 4.7545e-05 - accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "3825/3825 [==============================] - 0s 39us/step - loss: 4.4813e-05 - accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "3825/3825 [==============================] - 0s 42us/step - loss: 4.2325e-05 - accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "3825/3825 [==============================] - 0s 43us/step - loss: 3.9982e-05 - accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "3825/3825 [==============================] - 0s 38us/step - loss: 3.7806e-05 - accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "3825/3825 [==============================] - 0s 37us/step - loss: 3.5789e-05 - accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "3825/3825 [==============================] - 0s 37us/step - loss: 3.3905e-05 - accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "3825/3825 [==============================] - 0s 38us/step - loss: 3.2158e-05 - accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "3825/3825 [==============================] - 0s 37us/step - loss: 3.0493e-05 - accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "3825/3825 [==============================] - 0s 38us/step - loss: 2.8975e-05 - accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "3825/3825 [==============================] - 0s 37us/step - loss: 2.7525e-05 - accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "3825/3825 [==============================] - 0s 38us/step - loss: 2.6167e-05 - accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "3825/3825 [==============================] - 0s 38us/step - loss: 2.4903e-05 - accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "3825/3825 [==============================] - 0s 38us/step - loss: 2.3708e-05 - accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "3825/3825 [==============================] - 0s 38us/step - loss: 2.2577e-05 - accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "3825/3825 [==============================] - 0s 55us/step - loss: 2.1526e-05 - accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "3825/3825 [==============================] - 0s 49us/step - loss: 2.0526e-05 - accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "3825/3825 [==============================] - 0s 43us/step - loss: 1.9584e-05 - accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "3825/3825 [==============================] - 0s 68us/step - loss: 1.8696e-05 - accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "3825/3825 [==============================] - 0s 38us/step - loss: 1.7854e-05 - accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "3825/3825 [==============================] - 0s 36us/step - loss: 1.7064e-05 - accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "3825/3825 [==============================] - 0s 35us/step - loss: 1.6312e-05 - accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "3825/3825 [==============================] - 0s 46us/step - loss: 1.5598e-05 - accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "3825/3825 [==============================] - 0s 58us/step - loss: 1.4920e-05 - accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "3825/3825 [==============================] - 0s 37us/step - loss: 1.4278e-05 - accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "3825/3825 [==============================] - 0s 36us/step - loss: 1.3674e-05 - accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "3825/3825 [==============================] - 0s 37us/step - loss: 1.3092e-05 - accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "3825/3825 [==============================] - 0s 40us/step - loss: 1.2548e-05 - accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "3825/3825 [==============================] - 0s 40us/step - loss: 1.2018e-05 - accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "3825/3825 [==============================] - 0s 38us/step - loss: 1.1522e-05 - accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "3825/3825 [==============================] - 0s 36us/step - loss: 1.1048e-05 - accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "3825/3825 [==============================] - 0s 36us/step - loss: 1.0602e-05 - accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "3825/3825 [==============================] - 0s 35us/step - loss: 1.0170e-05 - accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "3825/3825 [==============================] - 0s 37us/step - loss: 9.7612e-06 - accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "3825/3825 [==============================] - 0s 38us/step - loss: 9.3692e-06 - accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "3825/3825 [==============================] - 0s 39us/step - loss: 8.9992e-06 - accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "3825/3825 [==============================] - 0s 37us/step - loss: 8.6426e-06 - accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "3825/3825 [==============================] - 0s 39us/step - loss: 8.3008e-06 - accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "3825/3825 [==============================] - 0s 37us/step - loss: 7.9769e-06 - accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "3825/3825 [==============================] - 0s 35us/step - loss: 7.6678e-06 - accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "3825/3825 [==============================] - 0s 35us/step - loss: 7.3694e-06 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 7.0861e-06 - accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 6.8147e-06 - accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "3825/3825 [==============================] - 0s 33us/step - loss: 6.5560e-06 - accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "3825/3825 [==============================] - 0s 33us/step - loss: 6.3074e-06 - accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "3825/3825 [==============================] - 0s 33us/step - loss: 6.0677e-06 - accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 5.8399e-06 - accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 5.6212e-06 - accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 5.4104e-06 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "3825/3825 [==============================] - 0s 33us/step - loss: 5.2112e-06 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "3825/3825 [==============================] - 0s 33us/step - loss: 5.0167e-06 - accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "3825/3825 [==============================] - 0s 33us/step - loss: 4.8327e-06 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 4.6548e-06 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "3825/3825 [==============================] - 0s 33us/step - loss: 4.4847e-06 - accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 4.3205e-06 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 4.1656e-06 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 4.0125e-06 - accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "3825/3825 [==============================] - 0s 33us/step - loss: 3.8687e-06 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "3825/3825 [==============================] - 0s 33us/step - loss: 3.7291e-06 - accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "3825/3825 [==============================] - 0s 33us/step - loss: 3.5947e-06 - accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 3.4668e-06 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 3.3437e-06 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 3.2246e-06 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 3.1095e-06 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "3825/3825 [==============================] - 0s 33us/step - loss: 2.9995e-06 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 2.8943e-06 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 2.7927e-06 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "3825/3825 [==============================] - 0s 33us/step - loss: 2.6944e-06 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 2.6007e-06 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 2.5096e-06 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 2.4222e-06 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 2.3383e-06 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "3825/3825 [==============================] - 0s 35us/step - loss: 2.2571e-06 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "3825/3825 [==============================] - 0s 37us/step - loss: 2.1791e-06 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "3825/3825 [==============================] - 0s 36us/step - loss: 2.1040e-06 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "3825/3825 [==============================] - 0s 36us/step - loss: 2.0315e-06 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "3825/3825 [==============================] - 0s 36us/step - loss: 1.9615e-06 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 1.8941e-06 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 1.8296e-06 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "3825/3825 [==============================] - 0s 35us/step - loss: 1.7670e-06 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "3825/3825 [==============================] - 0s 38us/step - loss: 1.7072e-06 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "3825/3825 [==============================] - 0s 35us/step - loss: 1.6485e-06 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "3825/3825 [==============================] - 0s 36us/step - loss: 1.5929e-06 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "3825/3825 [==============================] - 0s 35us/step - loss: 1.5388e-06 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 1.4869e-06 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 1.4363e-06 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "3825/3825 [==============================] - 0s 33us/step - loss: 1.3883e-06 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 1.3416e-06 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "3825/3825 [==============================] - 0s 35us/step - loss: 1.2965e-06 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "3825/3825 [==============================] - 0s 37us/step - loss: 1.2531e-06 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 1.2112e-06 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 1.1709e-06 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 1.1319e-06 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 1.0942e-06 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 1.0576e-06 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 1.0227e-06 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "3825/3825 [==============================] - 0s 70us/step - loss: 9.8890e-07 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "3825/3825 [==============================] - 0s 68us/step - loss: 9.5619e-07 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "3825/3825 [==============================] - 0s 51us/step - loss: 9.2461e-07 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "3825/3825 [==============================] - 0s 40us/step - loss: 8.9418e-07 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "3825/3825 [==============================] - 0s 66us/step - loss: 8.6482e-07 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "3825/3825 [==============================] - 0s 39us/step - loss: 8.3633e-07 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "3825/3825 [==============================] - 0s 34us/step - loss: 8.0896e-07 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "3825/3825 [==============================] - 0s 40us/step - loss: 7.8250e-07 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "3825/3825 [==============================] - 0s 48us/step - loss: 7.5685e-07 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "3825/3825 [==============================] - 0s 47us/step - loss: 7.3206e-07 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "3825/3825 [==============================] - 0s 43us/step - loss: 7.0834e-07 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "3825/3825 [==============================] - 0s 45us/step - loss: 6.8511e-07 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "3825/3825 [==============================] - 0s 47us/step - loss: 6.6304e-07 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "3825/3825 [==============================] - 0s 47us/step - loss: 6.4146e-07 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "3825/3825 [==============================] - 0s 46us/step - loss: 6.2069e-07 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "3825/3825 [==============================] - 0s 46us/step - loss: 6.0059e-07 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "3825/3825 [==============================] - 0s 47us/step - loss: 5.8126e-07 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "3825/3825 [==============================] - 0s 46us/step - loss: 5.6248e-07 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "3825/3825 [==============================] - 0s 55us/step - loss: 5.4446e-07 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "3825/3825 [==============================] - 0s 59us/step - loss: 5.2686e-07 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "3825/3825 [==============================] - 0s 45us/step - loss: 5.1000e-07 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "3825/3825 [==============================] - 0s 41us/step - loss: 4.9360e-07 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "3825/3825 [==============================] - 0s 38us/step - loss: 4.7789e-07 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "3825/3825 [==============================] - 0s 37us/step - loss: 4.6258e-07 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "3825/3825 [==============================] - 0s 67us/step - loss: 4.4792e-07 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "3825/3825 [==============================] - 0s 71us/step - loss: 4.3364e-07 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "3825/3825 [==============================] - 0s 38us/step - loss: 4.1981e-07 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "3825/3825 [==============================] - 0s 36us/step - loss: 4.0665e-07 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "3825/3825 [==============================] - 0s 47us/step - loss: 3.9367e-07 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "3825/3825 [==============================] - 0s 50us/step - loss: 3.8125e-07 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "3825/3825 [==============================] - 0s 50us/step - loss: 3.6916e-07 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "3825/3825 [==============================] - 0s 50us/step - loss: 3.5749e-07 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "3825/3825 [==============================] - 0s 39us/step - loss: 3.4618e-07 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "3825/3825 [==============================] - 0s 37us/step - loss: 3.3542e-07 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "3825/3825 [==============================] - 0s 47us/step - loss: 3.2475e-07 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "3825/3825 [==============================] - 0s 80us/step - loss: 3.1450e-07 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "3825/3825 [==============================] - 0s 54us/step - loss: 3.0477e-07 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "3825/3825 [==============================] - 0s 36us/step - loss: 2.9515e-07 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "3825/3825 [==============================] - 0s 42us/step - loss: 2.8597e-07 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "3825/3825 [==============================] - 0s 49us/step - loss: 2.7708e-07 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "3825/3825 [==============================] - 0s 51us/step - loss: 2.6851e-07 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "3825/3825 [==============================] - 0s 64us/step - loss: 2.6008e-07 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "3825/3825 [==============================] - 0s 40us/step - loss: 2.5200e-07 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "3825/3825 [==============================] - 0s 45us/step - loss: 2.4419e-07 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "3825/3825 [==============================] - 0s 63us/step - loss: 2.3661e-07 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "3825/3825 [==============================] - 0s 42us/step - loss: 2.2935e-07 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "3825/3825 [==============================] - 0s 40us/step - loss: 2.2229e-07 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "3825/3825 [==============================] - 0s 40us/step - loss: 2.1544e-07 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "3825/3825 [==============================] - 0s 42us/step - loss: 2.0882e-07 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "3825/3825 [==============================] - 0s 43us/step - loss: 2.0239e-07 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "3825/3825 [==============================] - 0s 48us/step - loss: 1.9622e-07 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "3825/3825 [==============================] - 0s 76us/step - loss: 1.9022e-07 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "3825/3825 [==============================] - 0s 63us/step - loss: 1.8442e-07 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "3825/3825 [==============================] - 0s 40us/step - loss: 1.7883e-07 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "3825/3825 [==============================] - 0s 43us/step - loss: 1.7339e-07 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "3825/3825 [==============================] - 0s 69us/step - loss: 1.6813e-07 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "3825/3825 [==============================] - 0s 41us/step - loss: 1.6305e-07 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "3825/3825 [==============================] - 0s 36us/step - loss: 1.5812e-07 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "3825/3825 [==============================] - 0s 39us/step - loss: 1.5336e-07 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "3825/3825 [==============================] - 0s 52us/step - loss: 1.4873e-07 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "3825/3825 [==============================] - 0s 40us/step - loss: 1.4425e-07 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "3825/3825 [==============================] - 0s 36us/step - loss: 1.3995e-07 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "3825/3825 [==============================] - 0s 37us/step - loss: 1.3573e-07 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "3825/3825 [==============================] - 0s 47us/step - loss: 1.3167e-07 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "3825/3825 [==============================] - 0s 69us/step - loss: 1.2776e-07 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "3825/3825 [==============================] - 0s 62us/step - loss: 1.2395e-07 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "3825/3825 [==============================] - 0s 41us/step - loss: 1.2028e-07 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.title('Training accuracy')\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "Test the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: Loss = 0.003374846804157035, accuracy = 0.9985185265541077\n"
     ]
    }
   ],
   "source": [
    "# START YOUR CODE HERE\n",
    "[test_loss, test_acc] = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Evaluation: Loss = {}, accuracy = {}\".format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "You've come to the end of this assignment, and you have built your first neural network. \n",
    "\n",
    "Congratulations on finishing this notebook! \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "8hb5s",
   "launcher_item_id": "5NrJ6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
