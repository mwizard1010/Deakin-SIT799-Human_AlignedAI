{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#  Adversarial Attack\n\nWe assume that you have read the [Adversarial Attacks Tutorial](./adversarial_attacks_tutorial.ipynb) carefully and run that notebook from scratch. \n\nIn this notebook, you are required to process adversarial attacks for a small subset of [ImageNet Dataset](http://www.image-net.org/). We prepared 100 images from different categories (in `./input_dir/`), and the labels are encoded in `./input_dir/clean_image.list`.\n\nFor evaluation, each adversarial image generated by the attack model will be fed to an evaluation model, and we will calculate the successful rate of adversarial attacks. **The adversarial images that can fool the evaluation model and also the perturbations are less than *Max_Distance* will be considered as a success**, where the perturbations are measured by the L2 distance between the adversarial image and original image.\n\nThere are three tasks:\n- **White-box attack**: the adversarial examples are crafted for the pretrained **MobileNetV2** model, and evaluated on the same **MobileNetV2** model.\n- **Black-box attack**: the adversarial examples are crafted for the pretrained **MobileNetV2** model, but evaluated on the **MobileNet** model, which is different from MobileNetV2.\n- **Black-box attack (after submission)**: you are required to submit the generated adversarial examples at last, and we will evaluate your adversarial examples on another model, which is invisible for you.\n\n### Goal\n\nWe provide a simple FGSM example here, and you are required to implement your own attack methods to **achieve the attack successful rate as high as possible** (for all three tasks).\n\nAt last, you are required to submit this jupyter notebook and the generated adversarial images.\nThe final grade will be scored according to the **white-box successful rate**, **black-box successful rate**, **white-box (after submission) successful rate**."
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Collecting Pillow\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/83/0fdb0910c909f40c090ba09184feb59001b7fcc89c676fb77986a262af85/Pillow-7.1.2-cp37-cp37m-macosx_10_10_x86_64.whl (2.2MB)\n\u001b[K     |████████████████████████████████| 2.2MB 2.1MB/s eta 0:00:01\n\u001b[?25hInstalling collected packages: Pillow\nSuccessfully installed Pillow-7.1.2\n\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.1.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
    }
   ],
   "source": "# ! pip3 install cython\n# ! pip3 install tensornets\n# ! pip3 install numpy==1.16.1\n! pip3 install Pillow\n\n"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": "import sys,os\nfrom PIL import Image\nimport numpy as np\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom time import perf_counter\nfrom utils import *\nimport tensornets as nets"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Device mapping:\n/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n\n"
    }
   ],
   "source": "import tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Load Images\nWe provided 100 images from different categories in `./input_dir/`, and the labels are encoded in `./input_dir/clean_image.list`."
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": "images = []\nwith open('./input_dir/clean_image.list', 'r') as f:\n    img_lines = f.readlines()\n    for img_line in img_lines:\n        imgname, label = img_line.strip('\\n').split(' ')\n        images.append((imgname, int(label)))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Image Processing\n\nEach input image must be preprocessed before fed into the models, such as normalization(subtracting the mean and then dividing by the standard deviation). In addition, each generated adversarial image must be reversely processed.\nNote that different pretrained models in Tensorflow require different preprocessing.\nWe provided several `preprocess` and `reverse_preprocess` function for different deep networks in `./utils.py`.\n\nBy default, the two functions are designed for mobilenet models.\n```python\npreprocess(image, model=\"mobilenet\")\nreverse_preprocess(image, model=\"mobilenet\")\n```\n\nIf you want to change to other models, see `./utils.py` for more details.\n\nWe have downloaded several popular pretrained models, you can adopt these models as the attacked model.\n## Pretrained Models in tensornets (nets)\n    'DenseNet121', 'DenseNet169', 'DenseNet201', \n    'Inception1', 'Inception2', 'Inception3', 'Inception4', 'InceptionResNet2',\n    'MobileNet25', 'MobileNet50', 'MobileNet75', MobileNet100', \n    'MobileNet35v2', 'MobileNet50v2', 'MobileNet75v2', 'MobileNet100v2', 'MobileNet130v2', 'MobileNet140v2', \n    'NASNetAlarge', 'NASNetAmobile', 'PNASNetlarge',\n    'ResNet50', 'ResNet101', 'ResNet152', 'ResNet50v2', 'ResNet101v2', 'ResNet152v2', 'ResNet200v2', \n    'ResNeXt50c32', 'ResNeXt101c32', 'ResNeXt101c64', 'WideResNet50',\n    'VGG16', 'VGG19', \n    'SqueezeNet'."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Define the Attack Method\n\n### TODO: implement your own attack methods.\n\n###  Tips:\n- We provide the simple FGSM attack method as an example here. You can try other attack methods (learned in this course), such as the iterative methods.\n- For black-box attack, we adopt the `MobileNetV2` as the attacked model, and the generated adversarial images may failed in `MobileNet` (which indicates poor transferability). You can try other attacked models (except `MobileNet`) or model ensemble."
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": "class Attack:\n    def __init__(self, input_image):\n        self.input_image = input_image\n        \n        # loss function\n        self.loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n        \n        # TODO: you may change your target model.\n        # load the model which will be attacked\n        self.attacked_model = nets.MobileNet50v2(input_image, reuse=tf.AUTO_REUSE)\n        \n    def generate_adversarial_example(self, input_label):\n        input_image = self.input_image\n        prediction = self.attacked_model\n        loss = self.loss_object(input_label, prediction)\n\n        # TODO: implement your own attack methods.\n        # Get the gradients of the loss w.r.t to the input image.\n        gradient = tf.gradients(loss, input_image)\n       \n        # Get the sign of the gradients to create the perturbation (FGSM)\n        signed_grad = tf.sign(gradient)[0]\n        # Epsilon in FGSM, you can try another value.\n        eps = 0.05\n        adv_image = input_image + eps * signed_grad\n       \n        # Clip the generated image between -1 and 1. Note that different pretrained models require different ranges.\n        adv_image = tf.clip_by_value(adv_image, -1, 1)\n       \n        # END TODO\n        input_image = self.input_image\n        \n        adv_image = input_image\n        g = 0.0\n        u = 1.0\n        eps = 0.001\n        \n        for t in range(1,16):\n            prediction = nets.MobileNet50v2(adv_image, reuse=tf.AUTO_REUSE)\n            loss = self.loss_object(input_label, prediction)\n            gradient = tf.gradients(loss, adv_image)\n            g = u*g + gradient[0]/tf.norm(gradient,ord=1)\n            adv_image = tf.clip_by_value(adv_image+eps/t*tf.sign(g)[0], -1, 1)\n            \n        return adv_image"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Evaluation\nDefine the evaluation functions for both white-box and black-box attack.\n**You are not allowed to modify these codes.**\n\n- For white-box attack, the adversarial images are evaluated on the `MobileNetv2` model.\n- For black-box attack, the adversarial images are evaluated on the `MobileNet` model. Therefore, you can not use the same `MobileNet` model as the attacked model.\n\nThe `Max_Distance` equals to 5.0 here."
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Device mapping:\n/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n\n"
    }
   ],
   "source": "Max_Distance = 5.0\n\nclass WhiteBox_Evaluation:\n    def __init__(self, adv_image):\n        self.adv_image = adv_image\n        self.eval_model = nets.MobileNet50v2(adv_image, reuse=tf.AUTO_REUSE)\n        \n    def get_adv_label(self):\n        adv_probs  = self.eval_model\n        adv_label = tf.argmax(adv_probs,1)\n        return adv_label\n    \nclass BlackBox_Evaluation:\n    def __init__(self, adv_image):\n        self.adv_image = adv_image\n        self.eval_model = nets.MobileNet50(adv_image, reuse=tf.AUTO_REUSE)\n        \n    def get_adv_label(self):\n        adv_probs  = self.eval_model\n        adv_label = tf.argmax(adv_probs,1)\n        return adv_label\n    \n# init the attacker\n\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nconfig.log_device_placement = True\nconfig.allow_soft_placement = True\nsess = tf.Session(config=config)\n\n# load and preprocess image\ninput_path = tf.placeholder(dtype=tf.string)\ninput_label = tf.placeholder(shape=None, dtype=tf.int32)\nimage_raw = tf.io.read_file(input_path)\nimage = tf.image.decode_jpeg(image_raw, channels=3)\nimage = image[None, ...]\n\ninput_image = preprocess(image)\nattacker = Attack(input_image)\n\n# generate adversarial example\nadv_image_t = attacker.generate_adversarial_example(input_label)\neval_model_white = WhiteBox_Evaluation(adv_image_t)\neval_model_black = BlackBox_Evaluation(adv_image_t)\n\n# measured by L2 distance\ndistance_t = tf.math.reduce_euclidean_norm(input_image - adv_image_t)\n\nadv_label_white_t = eval_model_white.get_adv_label()\nadv_label_black_t = eval_model_black.get_adv_label()\n\nsaved_image_t = reverse_preprocess(adv_image_t)[0]\n\nsess.run(tf.global_variables_initializer())\n_ = sess.run([attacker.attacked_model.pretrained(), eval_model_white.eval_model.pretrained(), eval_model_black.eval_model.pretrained()])\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# White-Box Attack Evaluation"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Tensor(\"Placeholder_5:0\", dtype=int32)\n"
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "labels must be 1-D, but got shape []\n\t [[node sparse_categorical_crossentropy_32/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at /usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]]\n\nOriginal stack trace for 'sparse_categorical_crossentropy_32/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits':\n  File \"/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/ipykernel/kernelapp.py\", line 597, in start\n    self.io_loop.start()\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/tornado/platform/asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/IPython/core/interactiveshell.py\", line 2858, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/IPython/core/interactiveshell.py\", line 2886, in _run_cell\n    return runner(coro)\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3063, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3254, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-20-9fb37e4464ac>\", line 42, in <module>\n    adv_image_t = attacker.generate_adversarial_example(input_label)\n  File \"<ipython-input-19-ac4a45924b8e>\", line 40, in generate_adversarial_example\n    loss = self.loss_object(input_label, prediction)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py\", line 126, in __call__\n    losses = self.call(y_true, y_pred)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py\", line 221, in call\n    return self.fn(y_true, y_pred, **self._fn_kwargs)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py\", line 978, in sparse_categorical_crossentropy\n    y_true, y_pred, from_logits=from_logits, axis=axis)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\", line 4546, in sparse_categorical_crossentropy\n    labels=target, logits=output)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\", line 3477, in sparse_softmax_cross_entropy_with_logits_v2\n    labels=labels, logits=logits, name=name)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\", line 3397, in sparse_softmax_cross_entropy_with_logits\n    precise_logits, labels, name=name)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\", line 11842, in sparse_softmax_cross_entropy_with_logits\n    labels=labels, name=name)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 793, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3360, in create_op\n    attrs, op_def, compute_device)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3429, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1751, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: labels must be 1-D, but got shape []\n\t [[{{node sparse_categorical_crossentropy_32/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-ce3f0480ce87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0madv_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0madv_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madv_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: labels must be 1-D, but got shape []\n\t [[node sparse_categorical_crossentropy_32/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at /usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]]\n\nOriginal stack trace for 'sparse_categorical_crossentropy_32/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits':\n  File \"/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/ipykernel/kernelapp.py\", line 597, in start\n    self.io_loop.start()\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/tornado/platform/asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/IPython/core/interactiveshell.py\", line 2858, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/IPython/core/interactiveshell.py\", line 2886, in _run_cell\n    return runner(coro)\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3063, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3254, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/Users/rbouadjenek/Library/Python/3.7/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-20-9fb37e4464ac>\", line 42, in <module>\n    adv_image_t = attacker.generate_adversarial_example(input_label)\n  File \"<ipython-input-19-ac4a45924b8e>\", line 40, in generate_adversarial_example\n    loss = self.loss_object(input_label, prediction)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py\", line 126, in __call__\n    losses = self.call(y_true, y_pred)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py\", line 221, in call\n    return self.fn(y_true, y_pred, **self._fn_kwargs)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py\", line 978, in sparse_categorical_crossentropy\n    y_true, y_pred, from_logits=from_logits, axis=axis)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\", line 4546, in sparse_categorical_crossentropy\n    labels=target, logits=output)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\", line 3477, in sparse_softmax_cross_entropy_with_logits_v2\n    labels=labels, logits=logits, name=name)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\", line 3397, in sparse_softmax_cross_entropy_with_logits\n    precise_logits, labels, name=name)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\", line 11842, in sparse_softmax_cross_entropy_with_logits\n    labels=labels, name=name)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 793, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3360, in create_op\n    attrs, op_def, compute_device)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3429, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1751, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": "success_cnt = 0\n\nfor idx, (imgname, label) in enumerate(images):\n    imgpath = './input_dir/' + imgname\n    run_list = [adv_image_t, distance_t, adv_label_white_t, saved_image_t]\n    feed_dict = {input_path: imgpath, input_label: label}\n    \n    \n    adv_image, distance, adv_label, saved_image = sess.run(run_list, feed_dict)\n    adv_label = adv_label[0]\n    \n    # if the adversarial image can successfully fool the attacked model, and the perturbations are less than Max_Distance\n    if distance <= Max_Distance:\n        success_cnt += 1 if adv_label != label else 0\n    \n    print('{}: clean_label={:3d} adv_label={:3d} distance={:.2f}'.format(imgname,label,adv_label,distance))\n    \n    # save the generated images to './output_dir'\n    saved_image = tf.image.encode_png(saved_image)\n    write_ops = tf.io.write_file('./output_dir/' + imgname, saved_image)\n    sess.run(write_ops)\n\nprint()\nprint('White-box attack successful rate: {}%'.format(success_cnt))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Black-Box Attack Evaluation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": "success_cnt = 0\n\nfor idx, (imgname, label) in enumerate(images):\n    imgpath = './input_dir/' + imgname\n    run_list = [adv_image_t, distance_t, adv_label_black_t, saved_image_t]\n    feed_dict = {input_path: imgpath, input_label: label}\n    \n    adv_image, distance, adv_label, saved_image = sess.run(run_list, feed_dict)\n    adv_label = adv_label[0]\n    \n    # if the adversarial image can successfully fool the attacked model, and the perturbations are less than Max_Distance\n    if distance <= Max_Distance:\n        success_cnt += 1 if adv_label != label else 0\n    \n    print('{}: clean_label={:3d} adv_label={:3d} distance={:.2f}'.format(imgname,label,adv_label,distance))\n    \n    # save the generated images to './output_dir'\n    saved_image = tf.image.encode_png(saved_image)\n    write_ops = tf.io.write_file('./output_dir/' + imgname, saved_image)\n    sess.run(write_ops)\n\nprint()\nprint('Black-box attack successful rate: {}%'.format(success_cnt))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
